{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "SEED = 123\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(SEED) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 64\n",
    "INPUT_SIZE = (256, 256)\n",
    "\n",
    "def count_files_in_directory(directory):\n",
    "    total_files = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        total_files += len(files)\n",
    "    return total_files\n",
    "\n",
    "main_data_dir = r\"C:\\Users\\Josh\\Desktop\\CUDA\\skindiseases\"\n",
    "train_dir = os.path.join(main_data_dir, \"train\")\n",
    "val_dir = os.path.join(main_data_dir, \"val\")\n",
    "test_dir = os.path.join(main_data_dir, \"test\")\n",
    "\n",
    "train_files = count_files_in_directory(train_dir)\n",
    "val_files = count_files_in_directory(val_dir)\n",
    "test_files = count_files_in_directory(test_dir)\n",
    "\n",
    "print(f\"Training Dataset: {train_files}\")\n",
    "print(f\"Validation Dataset: {val_files}\")\n",
    "print(f\"Test Dataset: {test_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the training dataset to calculate mean and std, and get class labels\n",
    "train_dataset = datasets.ImageFolder(root=train_dir)\n",
    "class_n = list(train_dataset.class_to_idx.keys())  # Automatically retrieves class names from folders\n",
    "print(\"Class to label mapping:\", train_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class KMeansSegmentation:\n",
    "    def __init__(self, n_clusters=8, overlay_alpha=0.5):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.overlay_alpha = overlay_alpha\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Convert PIL image to NumPy array\n",
    "        img_np = np.array(img)\n",
    "\n",
    "        # Reshape the image to a 2D array of pixels\n",
    "        pixel_values = img_np.reshape((-1, 3))\n",
    "        pixel_values = np.float32(pixel_values)\n",
    "\n",
    "        # Define criteria and apply K-means\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "        _, labels, centers = cv2.kmeans(pixel_values, self.n_clusters, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "        # Convert centers back to 8-bit values and reshape labels to the original image shape\n",
    "        centers = np.uint8(centers)\n",
    "        segmented_image = centers[labels.flatten()]\n",
    "        segmented_image = segmented_image.reshape(img_np.shape)\n",
    "\n",
    "        # Convert segmented image to grayscale to create a mask\n",
    "        gray_segmented = cv2.cvtColor(segmented_image, cv2.COLOR_RGB2GRAY)\n",
    "        _, mask = cv2.threshold(gray_segmented, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Blend the segmented regions back onto the original image\n",
    "        img_segmented = cv2.addWeighted(img_np, 1 - self.overlay_alpha, segmented_image, self.overlay_alpha, 0)\n",
    "\n",
    "        # Convert back to PIL Image\n",
    "        return Image.fromarray(img_segmented)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CLAHETransform:\n",
    "    def __init__(self, clip_limit=2.0, tile_grid_size=(8, 8)):\n",
    "        self.clip_limit = clip_limit\n",
    "        self.tile_grid_size = tile_grid_size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Convert PIL Image to NumPy array\n",
    "        img_np = np.array(img)\n",
    "        \n",
    "        # Apply CLAHE on each channel independently if it's a color image\n",
    "        if len(img_np.shape) == 3:\n",
    "            channels = cv2.split(img_np)\n",
    "            clahe = cv2.createCLAHE(clipLimit=self.clip_limit, tileGridSize=self.tile_grid_size)\n",
    "            channels = [clahe.apply(channel) for channel in channels]\n",
    "            img_np = cv2.merge(channels)\n",
    "        else:\n",
    "            # Apply CLAHE on grayscale images\n",
    "            clahe = cv2.createCLAHE(clipLimit=self.clip_limit, tileGridSize=self.tile_grid_size)\n",
    "            img_np = clahe.apply(img_np)\n",
    "\n",
    "        # Convert back to PIL Image\n",
    "        img_clahe = Image.fromarray(img_np)\n",
    "        return img_clahe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "MEAN = (0.6181, 0.4643, 0.4194)\n",
    "STD = (0.1927, 0.1677, 0.1617)\n",
    "\n",
    "\n",
    "# Define transformations\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(INPUT_SIZE),\n",
    "    CLAHETransform(clip_limit=2.0, tile_grid_size=(8, 8)),\n",
    "    transforms.RandomResizedCrop(227, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5), \n",
    "    transforms.RandomApply([KMeansSegmentation(n_clusters=3, overlay_alpha=0.5)], p=0.3),\n",
    "    transforms.RandomApply([transforms.RandomRotation(degrees=(-20, 20))], p=0.5),\n",
    "    transforms.RandomChoice([\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
    "        transforms.RandomGrayscale(p=0.2)\n",
    "    ]),\n",
    "    transforms.RandomApply([transforms.RandomAffine(degrees=5, translate=(0.02, 0.02), shear=2)], p=0.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=MEAN, std=STD)\n",
    "])\n",
    "\n",
    "transform_val_test = transforms.Compose([\n",
    "    transforms.Resize(INPUT_SIZE),\n",
    "    CLAHETransform(clip_limit=2.0, tile_grid_size=(8, 8)),\n",
    "    transforms.CenterCrop((227,227)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=MEAN, std=STD)\n",
    "])\n",
    "# Load the datasets with the new transforms\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform_train)\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=transform_val_test)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform_val_test)\n",
    "\n",
    "# Create DataLoaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of images and labels from the DataLoader\n",
    "images, labels = next(iter(train_loader))\n",
    "print(images.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to unnormalize the image for visualization\n",
    "def unnormalize(image, mean, std):\n",
    "    # Convert the tensor to a NumPy array and transpose dimensions to (H, W, C)\n",
    "    image = image.numpy().transpose((1, 2, 0))  \n",
    "    \n",
    "    # Unnormalize by reversing the mean and std normalization\n",
    "    image = (image * std) + mean  \n",
    "    \n",
    "    # Clip values to be between 0 and 1 for valid image display\n",
    "    image = np.clip(image, 0, 1)  \n",
    "    return image\n",
    "\n",
    "\n",
    "# Visualize a batch of images from the train_loader\n",
    "def visualize_loader(loader, mean, std, class_names, num_images=6):\n",
    "    # Get a batch of images\n",
    "    data_iter = iter(loader)\n",
    "    images, labels = next(data_iter)  \n",
    "\n",
    "    # Plot the images\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        image = unnormalize(images[i], mean, std)  \n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"Class: {class_names[labels[i]]}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Use this function to visualize a batch of images\n",
    "visualize_loader(train_loader, mean=MEAN, std=STD, class_names=class_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "model = models.alexnet(weights=None)  \n",
    "\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    *list(model.classifier.children())[:3]  \n",
    ")\n",
    "\n",
    "\n",
    "weight_path = r\"\"  \n",
    "state_dict = torch.load(weight_path, weights_only=True)\n",
    "\n",
    "\n",
    "new_state_dict = {}\n",
    "for k, v in state_dict.items():\n",
    "    new_key = k.replace(\"model.\", \"\") if k.startswith(\"model.\") else k\n",
    "    if new_key in model.state_dict().keys():\n",
    "        new_state_dict[new_key] = v\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "model.load_state_dict(new_state_dict, strict=False)  \n",
    "\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "model.eval()\n",
    "print(model)\n",
    "\n",
    "# from torchsummary import summary\n",
    "# input_size = (3, 227, 227)\n",
    "# summary(model, input_size=input_size, device=str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def extract_features(data_loader, model, device):\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    model.to(device)  # Move the model to the GPU\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for images, target_labels in data_loader:\n",
    "            images = images.to(device) \n",
    "            target_labels = target_labels.to(device)  \n",
    "\n",
    "            # Extract features using the model\n",
    "            output_features = model(images)\n",
    "            \n",
    "            # Move features back to the CPU and convert to NumPy arrays\n",
    "            features.append(output_features.cpu().numpy()) \n",
    "            labels.append(target_labels.cpu().numpy())\n",
    "    \n",
    "    # Concatenate features and labels from all batches\n",
    "    features = np.vstack(features)\n",
    "    labels = np.concatenate(labels)\n",
    "    return features, labels\n",
    "\n",
    "train_features, y_train = extract_features(train_loader, model, device)\n",
    "val_features, y_val = extract_features(val_loader, model, device)\n",
    "test_features, y_test = extract_features(test_loader, model, device)\n",
    "\n",
    "\n",
    "# Make sure the extracted features are in a format compatible with XGBoost\n",
    "print(\"Train features shape:\", train_features.shape)\n",
    "print(\"Validation features shape:\", val_features.shape)\n",
    "print(\"Test features shape:\", test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import plotly\n",
    "from xgboost import XGBClassifier\n",
    "import json\n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.02, 0.06, log=True), \n",
    "        'max_depth': trial.suggest_int('max_depth', 20, 30), \n",
    "        'n_estimators': trial.suggest_int('n_estimators', 300, 500),  \n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 3),  \n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 0.7),  \n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.7), \n",
    "    }\n",
    "\n",
    "\n",
    "    xgb_model = XGBClassifier(\n",
    "        objective='multi:softmax',\n",
    "        num_class=len(class_n),\n",
    "        random_state=SEED,\n",
    "        eval_metric='merror',\n",
    "        tree_method='hist',\n",
    "        device='cuda',  \n",
    "        early_stopping_rounds=20,\n",
    "        **params,\n",
    "    )\n",
    "\n",
    "    xgb_model.fit(\n",
    "        train_features, y_train,\n",
    "        eval_set=[(val_features, y_val)],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    accuracy = xgb_model.score(val_features, y_val)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=SEED)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "study.optimize(objective, n_trials=300)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"\\nBest hyperparameters found:\", best_params)\n",
    "\n",
    "best_value = study.best_value\n",
    "print(\"\\nBest value found:\", best_value)\n",
    "\n",
    "\n",
    "optimized_xgb_model = XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=len(class_n),\n",
    "    random_state=SEED,\n",
    "    eval_metric='merror',\n",
    "    tree_method='hist',\n",
    "    device='cuda',  \n",
    "    early_stopping_rounds=20,  \n",
    "    **best_params,\n",
    ")\n",
    "\n",
    "optimized_xgb_model.fit(\n",
    "    train_features, y_train,\n",
    "    eval_set=[(val_features, y_val)],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Save model and parameters\n",
    "optimized_xgb_model.save_model('final_xgboost_model.json')\n",
    "with open('best_hyperparameters.json', 'w') as f:\n",
    "    json.dump(best_params, f)\n",
    "print(\"Model and parameters saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_predictions = optimized_xgb_model.predict(train_features)\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "print(f'Training Accuracy: {train_accuracy * 100:.2f}%')\n",
    "\n",
    "val_predictions = optimized_xgb_model.predict(val_features)\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(f'Validation Accuracy: {val_accuracy * 100:.2f}%')\n",
    "\n",
    "test_predictions = optimized_xgb_model.predict(test_features)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tool",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
