{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "SEED = 42\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(SEED)  # Apply the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categories and the paths to datasets\n",
    "checkpoint_path = r'C:\\Users\\Josh\\Desktop\\CUDA\\52.41.pth'\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "INPUT_SIZE = (256, 256)\n",
    "\n",
    "def count_files_in_directory(directory):\n",
    "    total_files = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        total_files += len(files)\n",
    "    return total_files\n",
    "\n",
    "main_data_dir = r\"C:\\Users\\Josh\\Desktop\\CUDA\\splitdata\"\n",
    "train_dir = os.path.join(main_data_dir, \"train\")\n",
    "val_dir = os.path.join(main_data_dir, \"val\")\n",
    "test_dir = os.path.join(main_data_dir, \"test\")\n",
    "\n",
    "train_files = count_files_in_directory(train_dir)\n",
    "val_files = count_files_in_directory(val_dir)\n",
    "test_files = count_files_in_directory(test_dir)\n",
    "\n",
    "print(f\"Training Dataset: {train_files}\")\n",
    "print(f\"Validation Dataset: {val_files}\")\n",
    "print(f\"Test Dataset: {test_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the training dataset to calculate mean and std, and get class labels\n",
    "train_dataset = datasets.ImageFolder(root=train_dir)\n",
    "class_n = list(train_dataset.class_to_idx.keys())  # Automatically retrieves class names from folders\n",
    "print(\"Class to label mapping:\", train_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "MEAN = (0.6181, 0.4643, 0.4194)\n",
    "STD = (0.1927, 0.1677, 0.1617)\n",
    "\n",
    "\n",
    "class CLAHETransform:\n",
    "    def __init__(self, clip_limit=2.0, tile_grid_size=(8, 8)):\n",
    "        self.clip_limit = clip_limit\n",
    "        self.tile_grid_size = tile_grid_size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Convert PIL Image to NumPy array\n",
    "        img_np = np.array(img)\n",
    "        \n",
    "        # Apply CLAHE on each channel independently if it's a color image\n",
    "        if len(img_np.shape) == 3:\n",
    "            channels = cv2.split(img_np)\n",
    "            clahe = cv2.createCLAHE(clipLimit=self.clip_limit, tileGridSize=self.tile_grid_size)\n",
    "            channels = [clahe.apply(channel) for channel in channels]\n",
    "            img_np = cv2.merge(channels)\n",
    "        else:\n",
    "            # Apply CLAHE on grayscale images\n",
    "            clahe = cv2.createCLAHE(clipLimit=self.clip_limit, tileGridSize=self.tile_grid_size)\n",
    "            img_np = clahe.apply(img_np)\n",
    "\n",
    "        # Convert back to PIL Image\n",
    "        img_clahe = Image.fromarray(img_np)\n",
    "        return img_clahe\n",
    "\n",
    "# Define transformations\n",
    "transform_train = transforms.Compose([\n",
    "    # Resize to standardize input dimensions\n",
    "    transforms.Resize(INPUT_SIZE),\n",
    "    transforms.CenterCrop((227, 227)), \n",
    "\n",
    "    # Apply CLAHE\n",
    "    transforms.RandomApply([CLAHETransform(clip_limit=2.0, tile_grid_size=(8, 8))], p=0.5),\n",
    "\n",
    "    # Segmentation and rotations as defined previously\n",
    "    # KMeansSegmentation(n_clusters=10, p=0.3),\n",
    "    transforms.RandomApply([transforms.RandomRotation(degrees=(0, 20))], p=0.25),\n",
    "    transforms.RandomApply([transforms.RandomRotation(degrees=(0, 10))], p=0.25),\n",
    "    transforms.RandomApply([transforms.RandomRotation(degrees=(-20, 0))], p=0.25),\n",
    "    transforms.RandomApply([transforms.RandomRotation(degrees=(-10, 0))], p=0.25),\n",
    "\n",
    "    # Subtle affine transformations and other adjustments\n",
    "    transforms.RandomApply([transforms.RandomAffine(degrees=5, translate=(0.02, 0.02), shear=2)], p=0.3),\n",
    "    transforms.RandomApply([transforms.RandomPerspective(distortion_scale=0.05, p=0.2)], p=0.2),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5))], p=0.4),\n",
    "    transforms.RandomApply([transforms.ColorJitter(brightness=0.2, contrast=0.2)], p=0.7),\n",
    "    transforms.RandomApply([transforms.RandomGrayscale(p=1.0)], p=0.2),\n",
    "    transforms.RandomApply([transforms.RandomHorizontalFlip()], p=0.5),\n",
    "    transforms.RandomApply([transforms.RandomAdjustSharpness(sharpness_factor=1.5)], p=0.3),\n",
    "\n",
    "    # Convert to tensor and normalize\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=MEAN, std=STD)\n",
    "])\n",
    "\n",
    "# Validation and test transformations\n",
    "transform_val_test = transforms.Compose([\n",
    "    transforms.Resize(INPUT_SIZE),\n",
    "    transforms.CenterCrop((227, 227)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=MEAN, std=STD)\n",
    "])\n",
    "\n",
    "# Load the datasets with the new transforms\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform_train)\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=transform_val_test)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform_val_test)\n",
    "\n",
    "# Create DataLoaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of images and labels from the DataLoader\n",
    "images, labels = next(iter(train_loader))\n",
    "print(images.shape)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to unnormalize the image for visualization\n",
    "def unnormalize(image, mean, std):\n",
    "    # Convert the tensor to a NumPy array and transpose dimensions to (H, W, C)\n",
    "    image = image.numpy().transpose((1, 2, 0))  \n",
    "    \n",
    "    # Unnormalize by reversing the mean and std normalization\n",
    "    image = (image * std) + mean  \n",
    "    \n",
    "    # Clip values to be between 0 and 1 for valid image display\n",
    "    image = np.clip(image, 0, 1)  \n",
    "    return image\n",
    "\n",
    "\n",
    "# Visualize a batch of images from the train_loader\n",
    "def visualize_loader(loader, mean, std, class_names, num_images=6):\n",
    "    # Get a batch of images\n",
    "    data_iter = iter(loader)\n",
    "    images, labels = next(data_iter)  \n",
    "\n",
    "    # Plot the images\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        image = unnormalize(images[i], mean, std)  \n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"Class: {class_names[labels[i]]}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Use this function to visualize a batch of images\n",
    "visualize_loader(train_loader, mean=MEAN, std=STD, class_names=class_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class AlexNetFC6(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNetFC6, self).__init__()\n",
    "        alexnet = models.alexnet(pretrained=False)\n",
    "        self.features = alexnet.features\n",
    "        self.pooling = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.fc6 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.pooling(x) \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc6(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "alexnet_fc6 = AlexNetFC6()\n",
    "alexnet_fc6.load_state_dict(torch.load(checkpoint_path), strict=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "alexnet_fc6.to(device)\n",
    "alexnet_fc6.eval()  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data_loader, model):\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for images, target_labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Extract features using the custom AlexNet model (up to fc6)\n",
    "            output_features = model(images)\n",
    "            \n",
    "            # Append extracted features and labels to the list\n",
    "            features.append(output_features.cpu().numpy())  # Keeping this as CPU NumPy\n",
    "            labels.append(target_labels.cpu().numpy())\n",
    "    \n",
    "    # Concatenate features and labels from all batches\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    return features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from the datasets\n",
    "train_features, y_train = extract_features(train_loader, alexnet_fc6)\n",
    "val_features, y_val = extract_features(val_loader, alexnet_fc6)\n",
    "test_features, y_test = extract_features(test_loader, alexnet_fc6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameter search space with adjusted learning rate\n",
    "param_space = {\n",
    "    'learning_rate': (1e-2, 0.5, 'log-uniform'),  # Adjusted minimum learning rate\n",
    "    'max_depth': (2, 15),\n",
    "    'colsample_bytree': (0.3, 1.0, 'uniform'),\n",
    "    'colsample_bylevel': (0.3, 1.0, 'uniform'),\n",
    "    'subsample': (0.3, 1.0, 'uniform'),\n",
    "    'min_child_weight': (1, 50),\n",
    "    'gamma': (0, 10),\n",
    "    'reg_alpha': (1e-3, 200, 'log-uniform'),\n",
    "    'reg_lambda': (1e-3, 200, 'log-uniform'),\n",
    "    'scale_pos_weight': (0.1, 20.0, 'log-uniform'),\n",
    "    'max_delta_step': (0, 20),\n",
    "}\n",
    "\n",
    "# Initialize XGBClassifier with fixed parameters\n",
    "model = XGBClassifier(\n",
    "    n_estimators=1000,\n",
    "    objective='multi:softmax',\n",
    "    num_class=len(class_n),\n",
    "    random_state=SEED,\n",
    "    early_stopping_rounds=20,\n",
    "    verbosity=1  # Replace verbose with verbosity to avoid warnings\n",
    ")\n",
    "\n",
    "# Bayesian optimization with BayesSearchCV\n",
    "bayes_cv = BayesSearchCV(\n",
    "    estimator=model,\n",
    "    search_spaces=param_space,\n",
    "    n_iter=20,  # Number of search iterations\n",
    "    scoring='accuracy',\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    n_jobs=-1,\n",
    "    random_state=SEED,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the model using the validation set for early stopping\n",
    "bayes_cv.fit(\n",
    "    train_features, y_train,\n",
    "    eval_set=[(val_features, y_val)],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the best model as JSON\n",
    "best_model = bayes_cv.best_estimator_\n",
    "best_model.save_model('best_xgboost_model.json')  # Saves model in JSON format\n",
    "\n",
    "# Retrieve the best parameters and initialize final model with them for full training\n",
    "best_params = bayes_cv.best_params_\n",
    "final_model = XGBClassifier(\n",
    "    **best_params,\n",
    "    n_estimators=1000,\n",
    "    objective='multi:softmax',\n",
    "    num_class=len(class_n),\n",
    "    random_state=SEED,\n",
    "    early_stopping_rounds=20,\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "# Fit the final model on training data with validation monitoring\n",
    "final_model.fit(\n",
    "    train_features, y_train,\n",
    "    eval_set=[(train_features, y_train), (val_features, y_val)],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the final model after re-training if desired\n",
    "final_model.save_model('final_xgboost_model.json')  # Saves model as JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on training, validation, and test sets\n",
    "train_predictions = final_model.predict(train_features)\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "print(f'Training Accuracy: {train_accuracy * 100:.2f}%')\n",
    "\n",
    "val_predictions = final_model.predict(val_features)\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(f'Validation Accuracy: {val_accuracy * 100:.2f}%')\n",
    "\n",
    "test_predictions = final_model.predict(test_features)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate and print classification reports for validation and test sets\n",
    "val_classification_report = classification_report(y_val, val_predictions, target_names=class_n)\n",
    "print(\"Validation Classification Report:\\n\", val_classification_report)\n",
    "\n",
    "cm = confusion_matrix(y_val, val_predictions)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_n, yticklabels=class_n)\n",
    "\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "test_classification_report = classification_report(y_test, test_predictions, target_names=class_n)\n",
    "print(\"Test Classification Report:\\n\", test_classification_report)\n",
    "\n",
    "cm = confusion_matrix(y_test, test_predictions)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_n, yticklabels=class_n)\n",
    "\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
