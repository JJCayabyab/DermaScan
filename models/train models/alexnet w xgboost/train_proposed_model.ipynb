{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Program Title: train_proposed_model.ipynb\n",
    "Programmer/s: Idan Josh Bosi\n",
    "\n",
    "Where the program fits in the general system designs\n",
    "This program fits within a broader facial skin disease classification system, specifically handling the tasks of data preprocessing, \n",
    "feature extraction, and classification. It serves as the model training component, which takes raw image data, \n",
    "applies transformations and augmentations, and produces a trained model capable of accurately categorizing skin diseases.\n",
    "\n",
    "Date Written: October 4, 2024\n",
    "Date Revised: November 4, 2024\n",
    "\n",
    "Purpose:\n",
    "The primary purpose of this code is to preprocess images, extract features, and classify \n",
    "the images using a machine learning model optimized for multi-class facial skin disease identification.\n",
    "\n",
    "Data Structures, Algorithms, and Control:\n",
    "- Data structures: PyTorch DataLoader, NumPy arrays for data handling\n",
    "- Algorithms: AlexNet for feature extraction, K-means for segmentation and CLAHE transforms for preprocessing, and XGBoost for classification\n",
    "- Control: Structured as functions and classes to support modularity and reusability, \n",
    "with specific handling for image augmentation and feature extraction.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "SEED = 123\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(SEED) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 32\n",
    "INPUT_SIZE = (227, 227)\n",
    "\n",
    "def count_files_in_directory(directory):\n",
    "    total_files = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        total_files += len(files)\n",
    "    return total_files\n",
    "\n",
    "main_data_dir = r\"\"\n",
    "train_dir = os.path.join(main_data_dir, \"train\")\n",
    "val_dir = os.path.join(main_data_dir, \"val\")\n",
    "test_dir = os.path.join(main_data_dir, \"test\")\n",
    "\n",
    "train_files = count_files_in_directory(train_dir)\n",
    "val_files = count_files_in_directory(val_dir)\n",
    "test_files = count_files_in_directory(test_dir)\n",
    "\n",
    "print(f\"Training Dataset: {train_files}\")\n",
    "print(f\"Validation Dataset: {val_files}\")\n",
    "print(f\"Test Dataset: {test_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the training dataset to calculate mean and std, and get class labels\n",
    "train_dataset = datasets.ImageFolder(root=train_dir)\n",
    "class_n = list(train_dataset.class_to_idx.keys())  # Automatically retrieves class names from folders\n",
    "print(\"Class to label mapping:\", train_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "class KMeansSegmentation:\n",
    "    def __init__(self, n_clusters=3, overlay_alpha=0.5):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.overlay_alpha = overlay_alpha\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Convert PIL image to NumPy array\n",
    "        img_np = np.array(img)\n",
    "\n",
    "        # Reshape the image to a 2D array of pixels\n",
    "        h, w, c = img_np.shape\n",
    "        pixel_values = img_np.reshape((-1, 3))\n",
    "\n",
    "        # Apply K-Means clustering\n",
    "        kmeans = KMeans(n_clusters=self.n_clusters, random_state=42)\n",
    "        kmeans.fit(pixel_values)\n",
    "        centers = np.uint8(kmeans.cluster_centers_)\n",
    "        labels = kmeans.labels_\n",
    "\n",
    "        # Create the segmented image\n",
    "        segmented_image = centers[labels.flatten()]\n",
    "        segmented_image = segmented_image.reshape((h, w, c))\n",
    "\n",
    "        # Blend the segmented regions back onto the original image\n",
    "        img_segmented = cv2.addWeighted(img_np, 1 - self.overlay_alpha, segmented_image, self.overlay_alpha, 0)\n",
    "\n",
    "        # Convert back to PIL Image\n",
    "        return Image.fromarray(img_segmented)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLAHETransform:\n",
    "    def __init__(self, clip_limit=2.0, tile_grid_size=(8, 8)):\n",
    "        self.clip_limit = clip_limit\n",
    "        self.tile_grid_size = tile_grid_size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img_np = np.array(img)\n",
    "\n",
    "        img_lab = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)\n",
    "        l, a, b = cv2.split(img_lab)\n",
    "\n",
    "        clahe = cv2.createCLAHE(clipLimit=self.clip_limit, tileGridSize=self.tile_grid_size)\n",
    "        l_clahe = clahe.apply(l)\n",
    "\n",
    "        img_clahe = cv2.merge((l_clahe, a, b))\n",
    "        img_clahe = cv2.cvtColor(img_clahe, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "        return Image.fromarray(img_clahe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = (0.5960, 0.4489, 0.4046)\n",
    "STD = (0.2102, 0.1782, 0.1719)\n",
    "\n",
    "class CustomRotation:\n",
    "    def __init__(self, degrees, border_mode=cv2.BORDER_REPLICATE):\n",
    "        self.degrees = degrees\n",
    "        self.border_mode = border_mode\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img_array = np.array(img)\n",
    "        h, w = img_array.shape[:2]\n",
    "        center = (w // 2, h // 2)\n",
    "\n",
    "        angle = np.random.uniform(-self.degrees, self.degrees)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "\n",
    "        rotated_img = cv2.warpAffine(\n",
    "            img_array,\n",
    "            rotation_matrix,\n",
    "            (w, h),\n",
    "            flags=cv2.INTER_LINEAR,\n",
    "            borderMode=self.border_mode\n",
    "        )\n",
    "        return transforms.functional.to_pil_image(rotated_img)\n",
    "\n",
    "\n",
    "class CustomAffine:\n",
    "    def __init__(self, degrees, translate, shear, border_mode=cv2.BORDER_REPLICATE):\n",
    "        self.degrees = degrees\n",
    "        self.translate = translate\n",
    "        self.shear = shear\n",
    "        self.border_mode = border_mode\n",
    "\n",
    "    def __call__(self, img):\n",
    "\n",
    "        img_array = np.array(img)\n",
    "        \n",
    "\n",
    "        h, w = img_array.shape[:2]\n",
    "        \n",
    "        tx = np.random.uniform(-self.translate[0] * w, self.translate[0] * w)\n",
    "        ty = np.random.uniform(-self.translate[1] * h, self.translate[1] * h)\n",
    "        shear_x = np.random.uniform(-self.shear, self.shear)\n",
    "        shear_y = np.random.uniform(-self.shear, self.shear)\n",
    "\n",
    "        src_pts = np.float32([[0, 0], [w, 0], [0, h]])\n",
    "        dst_pts = np.float32([\n",
    "            [tx, ty],\n",
    "            [w + shear_x, ty],\n",
    "            [shear_x, h + shear_y]\n",
    "        ])\n",
    "        affine_matrix = cv2.getAffineTransform(src_pts, dst_pts)\n",
    "\n",
    "\n",
    "        affine_img = cv2.warpAffine(\n",
    "            img_array,\n",
    "            affine_matrix,\n",
    "            (w, h),\n",
    "            flags=cv2.INTER_LINEAR,\n",
    "            borderMode=self.border_mode\n",
    "        )\n",
    "        return transforms.functional.to_pil_image(affine_img)\n",
    "\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(INPUT_SIZE),  \n",
    "    transforms.RandomHorizontalFlip(p=0.5), \n",
    "    transforms.RandomApply([CustomRotation(degrees=20)], p=0.5), \n",
    "    transforms.RandomChoice([ \n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
    "        transforms.RandomGrayscale(p=0.1)\n",
    "    ]),\n",
    "    CLAHETransform(clip_limit=2.0, tile_grid_size=(8, 8)), \n",
    "    transforms.RandomApply([KMeansSegmentation(n_clusters=12, overlay_alpha=0.5)], p=0.1),  \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=MEAN, std=STD)  \n",
    "])\n",
    "\n",
    "\n",
    "transform_val_test = transforms.Compose([\n",
    "    transforms.Resize(INPUT_SIZE),\n",
    "    CLAHETransform(clip_limit=2.0, tile_grid_size=(8, 8)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=MEAN, std=STD)\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform_train)\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=transform_val_test)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform_val_test)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of images and labels from the DataLoader\n",
    "images, labels = next(iter(train_loader))\n",
    "print(images.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to unnormalize the image for visualization\n",
    "def unnormalize(image, mean, std):\n",
    "    # Convert the tensor to a NumPy array and transpose dimensions to (H, W, C)\n",
    "    image = image.numpy().transpose((1, 2, 0))  \n",
    "    \n",
    "    # Unnormalize by reversing the mean and std normalization\n",
    "    image = (image * std) + mean  \n",
    "    \n",
    "    # Clip values to be between 0 and 1 for valid image display\n",
    "    image = np.clip(image, 0, 1)  \n",
    "    return image\n",
    "\n",
    "\n",
    "# Visualize a batch of images from the train_loader\n",
    "def visualize_loader(loader, mean, std, class_names, num_images=6):\n",
    "    # Get a batch of images\n",
    "    data_iter = iter(loader)\n",
    "    images, labels = next(data_iter)  \n",
    "\n",
    "    # Plot the images\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        image = unnormalize(images[i], mean, std)  \n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"Class: {class_names[labels[i]]}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Use this function to visualize a batch of images\n",
    "visualize_loader(train_loader, mean=MEAN, std=STD, class_names=class_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "model = models.alexnet(weights=None)  \n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    *list(model.classifier.children())[:3]  \n",
    ")\n",
    "\n",
    "weight_path = r\"\"  \n",
    "state_dict = torch.load(weight_path, weights_only=True)\n",
    "\n",
    "new_state_dict = {}\n",
    "for k, v in state_dict.items():\n",
    "    new_key = k.replace(\"model.\", \"\") if k.startswith(\"model.\") else k\n",
    "    if new_key in model.state_dict().keys():\n",
    "        new_state_dict[new_key] = v\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(new_state_dict, strict=False)  \n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.eval()\n",
    "print(model)\n",
    "\n",
    "input_size = (3, 227, 227)\n",
    "summary(model, input_size=input_size, device=str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data_loader, model, device):\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    model.to(device)  # Move the model to the GPU\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for images, target_labels in data_loader:\n",
    "            images = images.to(device) \n",
    "            target_labels = target_labels.to(device)  \n",
    "\n",
    "            # Extract features using the model\n",
    "            output_features = model(images)\n",
    "            \n",
    "            # Move features back to the CPU and convert to NumPy arrays\n",
    "            features.append(output_features.cpu().numpy()) \n",
    "            labels.append(target_labels.cpu().numpy())\n",
    "    \n",
    "    # Concatenate features and labels from all batches\n",
    "    features = np.vstack(features)\n",
    "    labels = np.concatenate(labels)\n",
    "    return features, labels\n",
    "\n",
    "train_features, y_train = extract_features(train_loader, model, device)\n",
    "val_features, y_val = extract_features(val_loader, model, device)\n",
    "test_features, y_test = extract_features(test_loader, model, device)\n",
    "\n",
    "\n",
    "# Make sure the extracted features are in a format compatible with XGBoost\n",
    "print(\"Train features shape:\", train_features.shape)\n",
    "print(\"Validation features shape:\", val_features.shape)\n",
    "print(\"Test features shape:\", test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import plotly\n",
    "from xgboost import XGBClassifier\n",
    "import json\n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 5),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 10, 20),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.01, 1.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.1, 10.0, log=True),\n",
    "    }\n",
    "\n",
    "    xgb_model = XGBClassifier(\n",
    "        objective='multi:softmax',\n",
    "        num_class=len(class_n),\n",
    "        random_state=SEED,\n",
    "        eval_metric='merror',\n",
    "        tree_method='auto',\n",
    "        device='cuda',  \n",
    "        early_stopping_rounds=20,\n",
    "        **params,\n",
    "    )\n",
    "\n",
    "    xgb_model.fit(\n",
    "        train_features, y_train,\n",
    "        eval_set=[(val_features, y_val)],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    accuracy = xgb_model.score(val_features, y_val)\n",
    "    return accuracy\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=SEED)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"\\nBest hyperparameters found:\", best_params)\n",
    "\n",
    "best_value = study.best_value\n",
    "print(\"\\nBest value found:\", best_value)\n",
    "\n",
    "\n",
    "optimized_xgb_model = XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=len(class_n),\n",
    "    random_state=SEED,\n",
    "    eval_metric='merror',\n",
    "    tree_method='auto',\n",
    "    device='cuda',  \n",
    "    early_stopping_rounds=20,  \n",
    "    **best_params,\n",
    ")\n",
    "\n",
    "optimized_xgb_model.fit(\n",
    "    train_features, y_train,\n",
    "    eval_set=[(val_features, y_val)],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Save model and parameters\n",
    "optimized_xgb_model.save_model('final_xgboost_model.json')\n",
    "with open('best_hyperparameters.json', 'w') as f:\n",
    "    json.dump(best_params, f)\n",
    "print(\"Model and parameters saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_predictions = optimized_xgb_model.predict(train_features)\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "print(f'Training Accuracy: {train_accuracy * 100:.2f}%')\n",
    "\n",
    "val_predictions = optimized_xgb_model.predict(val_features)\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(f'Validation Accuracy: {val_accuracy * 100:.2f}%')\n",
    "\n",
    "test_predictions = optimized_xgb_model.predict(test_features)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tool",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
