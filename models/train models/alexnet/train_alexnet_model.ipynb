{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Program Title: train_alexnet_model.ipynb\n",
    "Programmer/s: Idan Josh Bosi \n",
    "\n",
    "Where the program fits in the general system designs: \n",
    "This script is a part of a larger project that involves facial skin disease classification using AlexNet. \n",
    "It focuses on training AlexNet from scratch for skin disease detection.\n",
    "\n",
    "Date Written: October 4, 2024\n",
    "Date Revised: November 4, 2024\n",
    "\n",
    "Purpose: \n",
    "The primary purpose of this script is to train a  AlexNet model to classify skin diseases into multiple classes. \n",
    "The script loads image datasets, applies augmentation techniques, performs training, and validates the model.\n",
    "\n",
    "Data Structures, Algorithms, and Control Flow:\n",
    "- The script primarily relies on PyTorch tensors and DataLoader for image data handling.\n",
    "- Uses K-means clustering and CLAHE transforms for preprocessing and data augmentation.\n",
    "- Utilizes a custom AlexNet model defined in PyTorch, with 8 output classes.\n",
    "- The training loop includes an early stopping mechanism and learning rate scheduler for optimization.\n",
    "- Implements visualization techniques for dataset samples and training/validation loss.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "SEED = 123\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(SEED)  # Apply the seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "INPUT_SIZE = (227, 227)  \n",
    "\n",
    "\n",
    "def count_files_in_directory(directory):\n",
    "    total_files = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        total_files += len(files)\n",
    "    return total_files\n",
    "\n",
    "main_data_dir = r\"\"\n",
    "train_dir = os.path.join(main_data_dir, \"train\")\n",
    "val_dir = os.path.join(main_data_dir, \"val\")\n",
    "test_dir = os.path.join(main_data_dir, \"test\")\n",
    "\n",
    "train_files = count_files_in_directory(train_dir)\n",
    "val_files = count_files_in_directory(val_dir)\n",
    "test_files = count_files_in_directory(test_dir)\n",
    "\n",
    "print(f\"Training Dataset: {train_files}\")\n",
    "print(f\"Validation Dataset: {val_files}\")\n",
    "print(f\"Test Dataset: {test_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the training dataset to calculate mean and std, and get class labels\n",
    "train_dataset = datasets.ImageFolder(root=train_dir)\n",
    "class_n = list(train_dataset.class_to_idx.keys())  # Automatically retrieves class names from folders\n",
    "print(\"Class to label mapping:\", train_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to calculate mean and std for the dataset\n",
    "# def calculate_mean_std(loader):\n",
    "#     mean = 0.0\n",
    "#     std = 0.0\n",
    "#     total_images_count = 0\n",
    "#     for images, _ in loader:\n",
    "#         batch_samples = images.size(0)  # batch size (the last batch can have smaller size!)\n",
    "#         images = images.view(batch_samples, images.size(1), -1)  # reshape to (batch_size, channels, height * width)\n",
    "#         mean += images.mean(2).sum(0)\n",
    "#         std += images.std(2).sum(0)\n",
    "#         total_images_count += batch_samples\n",
    "\n",
    "#     mean /= total_images_count\n",
    "#     std /= total_images_count\n",
    "#     return mean, std\n",
    "\n",
    "# # Temporary transform to load the dataset without normalization for mean and std calculation\n",
    "# transform_temp = transforms.Compose([\n",
    "#     transforms.Resize(INPUT_SIZE),\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "\n",
    "# # Load the training dataset without normalization\n",
    "# train_dataset_temp = datasets.ImageFolder(root=train_dir, transform=transform_temp)\n",
    "# train_loader_temp = DataLoader(train_dataset_temp, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# # Calculate mean and std\n",
    "# mean, std = calculate_mean_std(train_loader_temp)\n",
    "# print(f\"Calculated Mean: {mean}\")\n",
    "# print(f\"Calculated Std: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "class KMeansSegmentation:\n",
    "    def __init__(self, n_clusters=12, overlay_alpha=0.5):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.overlay_alpha = overlay_alpha\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Convert PIL image to NumPy array\n",
    "        img_np = np.array(img)\n",
    "\n",
    "        # Reshape the image to a 2D array of pixels\n",
    "        h, w, c = img_np.shape\n",
    "        pixel_values = img_np.reshape((-1, 3))\n",
    "\n",
    "        # Apply K-Means clustering\n",
    "        kmeans = KMeans(n_clusters=self.n_clusters, random_state=42)\n",
    "        kmeans.fit(pixel_values)\n",
    "        centers = np.uint8(kmeans.cluster_centers_)\n",
    "        labels = kmeans.labels_\n",
    "\n",
    "        # Create the segmented image\n",
    "        segmented_image = centers[labels.flatten()]\n",
    "        segmented_image = segmented_image.reshape((h, w, c))\n",
    "\n",
    "        # Blend the segmented regions back onto the original image\n",
    "        img_segmented = cv2.addWeighted(img_np, 1 - self.overlay_alpha, segmented_image, self.overlay_alpha, 0)\n",
    "\n",
    "        # Convert back to PIL Image\n",
    "        return Image.fromarray(img_segmented)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLAHETransform:\n",
    "    def __init__(self, clip_limit=2.0, tile_grid_size=(8, 8)):\n",
    "        self.clip_limit = clip_limit\n",
    "        self.tile_grid_size = tile_grid_size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img_np = np.array(img)\n",
    "\n",
    "        img_lab = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)\n",
    "        l, a, b = cv2.split(img_lab)\n",
    "\n",
    "        clahe = cv2.createCLAHE(clipLimit=self.clip_limit, tileGridSize=self.tile_grid_size)\n",
    "        l_clahe = clahe.apply(l)\n",
    "\n",
    "        img_clahe = cv2.merge((l_clahe, a, b))\n",
    "        img_clahe = cv2.cvtColor(img_clahe, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "        return Image.fromarray(img_clahe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = (0.5960, 0.4489, 0.4046)\n",
    "STD = (0.2102, 0.1782, 0.1719)\n",
    "\n",
    "class CustomRotation:\n",
    "    def __init__(self, degrees, border_mode=cv2.BORDER_REPLICATE):\n",
    "        self.degrees = degrees\n",
    "        self.border_mode = border_mode\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img_array = np.array(img)\n",
    "        h, w = img_array.shape[:2]\n",
    "        center = (w // 2, h // 2)\n",
    "\n",
    "        angle = np.random.uniform(-self.degrees, self.degrees)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "\n",
    "        rotated_img = cv2.warpAffine(\n",
    "            img_array,\n",
    "            rotation_matrix,\n",
    "            (w, h),\n",
    "            flags=cv2.INTER_LINEAR,\n",
    "            borderMode=self.border_mode\n",
    "        )\n",
    "        return transforms.functional.to_pil_image(rotated_img)\n",
    "\n",
    "\n",
    "class CustomAffine:\n",
    "    def __init__(self, degrees, translate, shear, border_mode=cv2.BORDER_REPLICATE):\n",
    "        self.degrees = degrees\n",
    "        self.translate = translate\n",
    "        self.shear = shear\n",
    "        self.border_mode = border_mode\n",
    "\n",
    "    def __call__(self, img):\n",
    "\n",
    "        img_array = np.array(img)\n",
    "        \n",
    "\n",
    "        h, w = img_array.shape[:2]\n",
    "        \n",
    "        tx = np.random.uniform(-self.translate[0] * w, self.translate[0] * w)\n",
    "        ty = np.random.uniform(-self.translate[1] * h, self.translate[1] * h)\n",
    "        shear_x = np.random.uniform(-self.shear, self.shear)\n",
    "        shear_y = np.random.uniform(-self.shear, self.shear)\n",
    "\n",
    "        src_pts = np.float32([[0, 0], [w, 0], [0, h]])\n",
    "        dst_pts = np.float32([\n",
    "            [tx, ty],\n",
    "            [w + shear_x, ty],\n",
    "            [shear_x, h + shear_y]\n",
    "        ])\n",
    "        affine_matrix = cv2.getAffineTransform(src_pts, dst_pts)\n",
    "\n",
    "\n",
    "        affine_img = cv2.warpAffine(\n",
    "            img_array,\n",
    "            affine_matrix,\n",
    "            (w, h),\n",
    "            flags=cv2.INTER_LINEAR,\n",
    "            borderMode=self.border_mode\n",
    "        )\n",
    "        return transforms.functional.to_pil_image(affine_img)\n",
    "\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(INPUT_SIZE),  \n",
    "    transforms.RandomHorizontalFlip(p=0.5), \n",
    "    transforms.RandomApply([CustomRotation(degrees=20)], p=0.5), \n",
    "    transforms.RandomChoice([ \n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
    "        transforms.RandomGrayscale(p=0.1)\n",
    "    ]),\n",
    "    CLAHETransform(clip_limit=2.0, tile_grid_size=(8, 8)), \n",
    "    transforms.RandomApply([KMeansSegmentation(n_clusters=12, overlay_alpha=0.5)], p=0.1),  \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=MEAN, std=STD)  \n",
    "])\n",
    "\n",
    "\n",
    "transform_val_test = transforms.Compose([\n",
    "    transforms.Resize(INPUT_SIZE),\n",
    "    CLAHETransform(clip_limit=2.0, tile_grid_size=(8, 8)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=MEAN, std=STD)\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform_train)\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=transform_val_test)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform_val_test)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "print(images.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to unnormalize the image for visualization\n",
    "def unnormalize(image, mean, std):\n",
    "    image = image.numpy().transpose((1, 2, 0))  \n",
    "    image = (image * std) + mean  \n",
    "    image = np.clip(image, 0, 1)  \n",
    "    return image\n",
    "\n",
    "\n",
    "# Visualize a batch of images from the train_loader\n",
    "def visualize_loader(loader, mean, std, class_names, num_images=6):\n",
    "    data_iter = iter(loader)\n",
    "    images, labels = next(data_iter)  \n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        image = unnormalize(images[i], mean, std)  \n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"Class: {class_names[labels[i]]}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_loader(train_loader, mean=MEAN, std=STD, class_names=class_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=len(class_n)):  \n",
    "        super(AlexNet, self).__init__()\n",
    "        \n",
    "        self.model = models.alexnet(weights=None)\n",
    "        self.model.classifier[6] = nn.Linear(4096, num_classes)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "alexnet = AlexNet(num_classes=len(class_n))\n",
    "device = torch.device(\"cuda\") \n",
    "alexnet.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(alexnet.parameters(), lr=1e-4, weight_decay=1e-4) \n",
    "\n",
    "summary(alexnet, input_size=(3, 227, 227))\n",
    "print(alexnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "PATIENCE = 5\n",
    "MODEL_PATH = 'alexnet.pth'\n",
    "LOG_FILE = 'training_logs.txt'  # Path to save the logs\n",
    "\n",
    "# Training Loop\n",
    "def train_model(model, train_loader, val_loader, epochs, criterion, optimizer, device, patience, save_path=MODEL_PATH, log_file=LOG_FILE):\n",
    "    # Initialize tracking metrics\n",
    "    train_metrics = {'loss': [], 'accuracy': []}\n",
    "    val_metrics = {'loss': [], 'accuracy': []}\n",
    "\n",
    "    best_val_accuracy = 0.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Ensure the log file is empty before starting\n",
    "    if os.path.exists(log_file):\n",
    "        open(log_file, 'w').close()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "        # Train phase\n",
    "        train_loss, train_accuracy = run_epoch(\n",
    "            model, train_loader, criterion, optimizer, device, is_training=True\n",
    "        )\n",
    "        train_metrics['loss'].append(train_loss)\n",
    "        train_metrics['accuracy'].append(train_accuracy)\n",
    "\n",
    "        # Validation phase\n",
    "        val_loss, val_accuracy = run_epoch(\n",
    "            model, val_loader, criterion, optimizer, device, is_training=False\n",
    "        )\n",
    "        val_metrics['loss'].append(val_loss)\n",
    "        val_metrics['accuracy'].append(val_accuracy)\n",
    "\n",
    "        # Logging metrics to console\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}%\")\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}%\")\n",
    "\n",
    "        # Save logs to file\n",
    "        with open(log_file, 'a') as f:\n",
    "            f.write(f\"Epoch {epoch + 1}/{epochs}\\n\")\n",
    "            f.write(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}%\\n\")\n",
    "            f.write(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}%\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            patience_counter = 0\n",
    "            print(f\"New best validation accuracy: {best_val_accuracy:.4f}%. Saving model...\")\n",
    "            with open(log_file, 'a') as f:\n",
    "                f.write(f\"New best validation accuracy: {best_val_accuracy:.4f}% - Model saved.\\n\")\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}.\")\n",
    "                with open(log_file, 'a') as f:\n",
    "                    f.write(f\"Early stopping triggered at epoch {epoch + 1}.\\n\")\n",
    "                break\n",
    "\n",
    "    print(f\"\\nTraining complete. Best validation accuracy: {best_val_accuracy:.4f}%\")\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(f\"Training complete. Best validation accuracy: {best_val_accuracy:.4f}%\\n\")\n",
    "    return train_metrics, val_metrics\n",
    "\n",
    "# Function to run a single epoch\n",
    "def run_epoch(model, data_loader, criterion, optimizer, device, is_training):\n",
    "    phase = \"Training\" if is_training else \"Validation\"\n",
    "    model.train() if is_training else model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with tqdm(data_loader, unit=\"batch\") as tepoch:\n",
    "        tepoch.set_description(f\"{phase} Phase\")\n",
    "        for inputs, labels in tepoch:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            if is_training:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            if is_training:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            tepoch.set_postfix(loss=f\"{running_loss / len(data_loader):.4f}\", accuracy=f\"{100 * correct / total:.4f}\")\n",
    "\n",
    "    epoch_loss = running_loss / len(data_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "\n",
    "train_metrics, val_metrics = train_model(\n",
    "    alexnet, train_loader, val_loader, EPOCHS, criterion, optimizer, device, patience=PATIENCE, save_path=MODEL_PATH, log_file=LOG_FILE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract loss values for plotting\n",
    "train_losses = train_metrics['loss']\n",
    "val_losses = val_metrics['loss']\n",
    "\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_losses(train_losses, val_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tool",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
