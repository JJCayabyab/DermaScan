{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2\n",
    "\n",
    "SEED = 123\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and Parameters\n",
    "checkpoint_path = r''  # Path to AlexNet model weights\n",
    "xgb_model_path = r''\n",
    "\n",
    "INPUT_SIZE = (227,227)\n",
    "MEAN = (0.5960, 0.4489, 0.4046)\n",
    "STD = (0.2102, 0.1782, 0.1719)\n",
    "\n",
    "main_data_dir = r\"\"\n",
    "val_dir = os.path.join(main_data_dir, \"val\")\n",
    "test_dir = os.path.join(main_data_dir, \"test\")\n",
    "\n",
    "val_dataset = datasets.ImageFolder(root=val_dir)\n",
    "class_names = list(val_dataset.classes)\n",
    "print(\"Class to label mapping:\", val_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLAHETransform:\n",
    "    def __init__(self, clip_limit=2.0, tile_grid_size=(8, 8)):\n",
    "        self.clip_limit = clip_limit\n",
    "        self.tile_grid_size = tile_grid_size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img_np = np.array(img)\n",
    "\n",
    "        img_lab = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)\n",
    "        l, a, b = cv2.split(img_lab)\n",
    "\n",
    "        clahe = cv2.createCLAHE(clipLimit=self.clip_limit, tileGridSize=self.tile_grid_size)\n",
    "        l_clahe = clahe.apply(l)\n",
    "\n",
    "        img_clahe = cv2.merge((l_clahe, a, b))\n",
    "        img_clahe = cv2.cvtColor(img_clahe, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "        return Image.fromarray(img_clahe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_val_test = transforms.Compose([\n",
    "    transforms.Resize(INPUT_SIZE),\n",
    "    CLAHETransform(clip_limit=2.0, tile_grid_size=(8, 8)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=MEAN, std=STD)\n",
    "])\n",
    "\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=transform_val_test)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform_val_test)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset,  shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "model = models.alexnet(weights=None)  \n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    *list(model.classifier.children())[:3]  \n",
    ")\n",
    "\n",
    "state_dict = torch.load(checkpoint_path, weights_only=True)\n",
    "\n",
    "new_state_dict = {}\n",
    "for k, v in state_dict.items():\n",
    "    new_key = k.replace(\"model.\", \"\") if k.startswith(\"model.\") else k\n",
    "    if new_key in model.state_dict().keys():\n",
    "        new_state_dict[new_key] = v\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(new_state_dict, strict=False)  \n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "model.eval()\n",
    "print(f\"Loaded model from {checkpoint_path}\")\n",
    "print(model)\n",
    "\n",
    "# from torchsummary import summary\n",
    "# input_size = (3, 227, 227)\n",
    "# summary(model, input_size=input_size, device=str(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.load_model(xgb_model_path)\n",
    "print(f\"Loaded XGBoost model from {xgb_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(data_loader, set_name, export_txt=False):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    image_paths = []  # To store image file paths\n",
    "    confidences = []  # To store confidence scores\n",
    "\n",
    "    # Access the dataset from the DataLoader to get image file paths\n",
    "    dataset = data_loader.dataset\n",
    "\n",
    "    for idx, (images, labels) in enumerate(tqdm(data_loader, desc=f\"Evaluating {set_name}\")):\n",
    "        images = images.to(device)\n",
    "        labels = labels.cpu().numpy()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            features = model(images).cpu().numpy()\n",
    "        probabilities = xgb_model.predict_proba(features)  # Get probabilities for each class\n",
    "        predictions = np.argmax(probabilities, axis=1)  # Predicted labels\n",
    "        confidence_scores = np.max(probabilities, axis=1) * 100   # Confidence scores for predicted labels\n",
    "\n",
    "        true_labels.extend(labels)\n",
    "        predicted_labels.extend(predictions)\n",
    "        confidences.extend(confidence_scores)\n",
    "\n",
    "        # Collect image file paths from the dataset\n",
    "        image_paths.extend([dataset.samples[i][0] for i in range(idx, idx + len(images))])\n",
    "\n",
    "    # Calculate and print accuracy\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    print(f\"\\n{set_name} Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Print classification report\n",
    "    print(f\"\\n{set_name} Classification Report:\\n\")\n",
    "    print(classification_report(true_labels, predicted_labels, target_names=class_names))\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title(f'{set_name} Confusion Matrix on AlexNet With XGBoost')\n",
    "    plt.show()\n",
    "\n",
    "    if export_txt:\n",
    "        output_file = f\"{set_name}_with_xgb_predictions.txt\"\n",
    "        with open(output_file, \"w\") as file:\n",
    "            file.write(\"Image File, True Label, Predicted Label, Confidence\\n\")\n",
    "            for img_path, true_label, pred_label, confidence in zip(image_paths, true_labels, predicted_labels, confidences):\n",
    "                true_class_name = class_names[true_label]\n",
    "                pred_class_name = class_names[pred_label]\n",
    "                file.write(f\"{img_path}, {true_class_name}, {pred_class_name}, {confidence:.2f}%\\n\")\n",
    "        print(f\"Predictions saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evaluate_model(val_loader, \"Validation Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(test_loader, \"Test Set\", export_txt=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
